{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_Light_Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlTODKN3yLW"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "sys.path.append('../')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxL5AHQ55eIz"
      },
      "source": [
        "LABEL_PERSON = 1\n",
        "LABEL_CAR = 3\n",
        "LABEL_BUS = 6\n",
        "LABEL_TRUCK = 8\n",
        "LABEL_TRAFFIC_LIGHT = 10\n",
        "LABEL_STOP_SIGN = 13\n",
        " \n",
        "def accept_box(boxes, box_index, tolerance):\n",
        "  \"\"\"\n",
        "  Eliminate duplicate bounding boxes.\n",
        "  \"\"\"\n",
        "  box = boxes[box_index]\n",
        "\n",
        "  for idx in range(box_index):\n",
        "    other_box = boxes[idx]\n",
        "    if abs(center(other_box, \"x\") - center(box, \"x\")) < tolerance and abs(center(other_box, \"y\") - center(box, \"y\")) < tolerance:\n",
        "      return False\n",
        " \n",
        "  return True\n",
        " \n",
        "def get_files(pattern):\n",
        "  \"\"\"\n",
        "  Create a list of all the images in a directory\n",
        "     \n",
        "  :param:pattern str The pattern of the filenames\n",
        "  :return: A list of the files that match the specified pattern \n",
        "  \"\"\"\n",
        "  files = []\n",
        " \n",
        "  # For each file that matches the specified pattern\n",
        "  for file_name in glob.iglob(pattern, recursive=True):\n",
        " \n",
        "    # Add the image file to the list of files\n",
        "    files.append(file_name)\n",
        " \n",
        "  # Return the complete file list\n",
        "  return files\n",
        "     \n",
        "def load_model(model_name):\n",
        "  \"\"\"\n",
        "  Download a pretrained object detection model, and save it to your hard drive.\n",
        "  :param:str Name of the pretrained object detection model\n",
        "  \"\"\"\n",
        "  url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + model_name + '.tar.gz'\n",
        "     \n",
        "  # Download a file from a URL that is not already in the cache\n",
        "  model_dir = tf.keras.utils.get_file(fname=model_name, untar=True, origin=url)\n",
        " \n",
        "  print(\"Model path: \", str(model_dir))\n",
        "   \n",
        "  model_dir = str(model_dir) + \"/saved_model\"\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        " \n",
        "  return model\n",
        " \n",
        "def load_rgb_images(pattern, shape=None):\n",
        "  \"\"\"\n",
        "  Loads the images in RGB format.\n",
        "     \n",
        "  :param:pattern str The pattern of the filenames\n",
        "  :param:shape Image dimensions (width, height)\n",
        "  \"\"\"\n",
        "  # Get a list of all the image files in a directory\n",
        "  files = get_files(pattern)\n",
        " \n",
        "  # For each image in the directory, convert it from BGR format to RGB format\n",
        "  images = [cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB) for file in files]\n",
        " \n",
        "  # Resize the image if the desired shape is provided\n",
        "  if shape:\n",
        "    return [cv2.resize(img, shape) for img in images]\n",
        "  else:\n",
        "    return images\n",
        " \n",
        "def load_ssd_coco():\n",
        "  \"\"\"\n",
        "  Load the neural network that has the SSD architecture, trained on the COCO\n",
        "  data set.\n",
        "  \"\"\"\n",
        "  return load_model(\"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\")\n",
        " \n",
        "def save_image_annotated(img_rgb, file_name, output, model_traffic_lights=None):\n",
        "  \"\"\"\n",
        "  Annotate the image with the object types, and generate cropped images of\n",
        "  traffic lights.\n",
        "  \"\"\"\n",
        "  # Create annotated image file \n",
        "  output_file = file_name.replace('.jpg', '_test.jpg')\n",
        "     \n",
        "  # For each bounding box that was detected  \n",
        "  for idx in range(len(output['boxes'])):\n",
        " \n",
        "    # Extract the type of the object that was detected\n",
        "    obj_class = output[\"detection_classes\"][idx]\n",
        "     \n",
        "    # How confident the object detection model is on the object's type\n",
        "    score = int(output[\"detection_scores\"][idx] * 100)\n",
        "         \n",
        "    # Extract the bounding box\n",
        "    box = output[\"boxes\"][idx]\n",
        " \n",
        "    color = None\n",
        "    label_text = \"\"\n",
        " \n",
        "    if obj_class == LABEL_PERSON:\n",
        "      color = (0, 255, 255)\n",
        "      label_text = \"Person \" + str(score)\n",
        "    if obj_class == LABEL_CAR:\n",
        "      color = (255, 255, 0)\n",
        "      label_text = \"Car \" + str(score)\n",
        "    if obj_class == LABEL_BUS:\n",
        "      color = (255, 255, 0)\n",
        "      label_text = \"Bus \" + str(score)\n",
        "    if obj_class == LABEL_TRUCK:\n",
        "      color = (255, 255, 0)\n",
        "      label_text = \"Truck \" + str(score)\n",
        "    if obj_class == LABEL_STOP_SIGN:\n",
        "      color = (128, 0, 0)\n",
        "      label_text = \"Stop Sign \" + str(score)\n",
        "    if obj_class == LABEL_TRAFFIC_LIGHT:\n",
        "      color = (255, 255, 255)\n",
        "      label_text = \"Traffic Light \" + str(score)\n",
        "             \n",
        "      if model_traffic_lights:\n",
        "       \n",
        "              # Annotate the image and save it\n",
        "        img_traffic_light = img_rgb[box[\"y\"]:box[\"y2\"], box[\"x\"]:box[\"x2\"]]\n",
        "        img_inception = cv2.resize(img_traffic_light, (299, 299))\n",
        "         \n",
        "                # Uncomment this if you want to save a cropped image of the traffic light\n",
        "        #cv2.imwrite(output_file.replace('.jpg', '_crop.jpg'), cv2.cvtColor(img_inception, cv2.COLOR_RGB2BGR))\n",
        "        img_inception = np.array([preprocess_input(img_inception)])\n",
        " \n",
        "        prediction = model_traffic_lights.predict(img_inception)\n",
        "        label = np.argmax(prediction)\n",
        "        score_light = str(int(np.max(prediction) * 100))\n",
        "        if label == 0:\n",
        "          label_text = \"Green \" + score_light\n",
        "        elif label == 1:\n",
        "          label_text = \"Yellow \" + score_light\n",
        "        elif label == 2:\n",
        "          label_text = \"Red \" + score_light\n",
        "        else:\n",
        "          label_text = 'NO-LIGHT'  # This is not a traffic light\n",
        " \n",
        "    if color and label_text and accept_box(output[\"boxes\"], idx, 5.0) and score > 70:\n",
        "      cv2.rectangle(img_rgb, (box[\"x\"], box[\"y\"]), (box[\"x2\"], box[\"y2\"]), color, 2)\n",
        "      cv2.putText(img_rgb, label_text, (box[\"x\"], box[\"y\"]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        " \n",
        "  cv2.imwrite(output_file, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "  print(output_file)\n",
        " \n",
        "def center(box, coord_type):\n",
        "  \"\"\"\n",
        "  Get center of the bounding box.\n",
        "  \"\"\"\n",
        "  return (box[coord_type] + box[coord_type + \"2\"]) / 2\n",
        " \n",
        "def perform_object_detection(model, file_name, save_annotated=False, model_traffic_lights=None):\n",
        "  \"\"\"\n",
        "  Perform object detection on an image using the predefined neural network.\n",
        "  \"\"\"\n",
        "  # Store the image\n",
        "  img_bgr = cv2.imread(file_name)\n",
        "  img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "  input_tensor = tf.convert_to_tensor(img_rgb) # Input needs to be a tensor\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        " \n",
        "  # Run the model\n",
        "  output = model(input_tensor)\n",
        " \n",
        "  print(\"num_detections:\", output['num_detections'], int(output['num_detections']))\n",
        " \n",
        "  # Convert the tensors to a NumPy array\n",
        "  num_detections = int(output.pop('num_detections'))\n",
        "  output = {key: value[0, :num_detections].numpy()\n",
        "            for key, value in output.items()}\n",
        "  output['num_detections'] = num_detections\n",
        " \n",
        "  print('Detection classes:', output['detection_classes'])\n",
        "  print('Detection Boxes:', output['detection_boxes'])\n",
        " \n",
        "  # The detected classes need to be integers.\n",
        "  output['detection_classes'] = output['detection_classes'].astype(np.int64)\n",
        "  output['boxes'] = [\n",
        "    {\"y\": int(box[0] * img_rgb.shape[0]), \"x\": int(box[1] * img_rgb.shape[1]), \"y2\": int(box[2] * img_rgb.shape[0]),\n",
        "     \"x2\": int(box[3] * img_rgb.shape[1])} for box in output['detection_boxes']]\n",
        " \n",
        "  if save_annotated:\n",
        "    save_image_annotated(img_rgb, file_name, output, model_traffic_lights)\n",
        " \n",
        "  return img_rgb, output, file_name\n",
        "     \n",
        "def perform_object_detection_video(model, video_frame, model_traffic_lights=None):\n",
        "  \"\"\"\n",
        "  Perform object detection on a video using the predefined neural network.\n",
        "     \n",
        "  Returns the annotated video frame.\n",
        "  \"\"\"\n",
        "  # Store the image\n",
        "  img_rgb = cv2.cvtColor(video_frame, cv2.COLOR_BGR2RGB)\n",
        "  input_tensor = tf.convert_to_tensor(img_rgb) # Input needs to be a tensor\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        " \n",
        "  # Run the model\n",
        "  output = model(input_tensor)\n",
        " \n",
        "  # Convert the tensors to a NumPy array\n",
        "  num_detections = int(output.pop('num_detections'))\n",
        "  output = {key: value[0, :num_detections].numpy()\n",
        "            for key, value in output.items()}\n",
        "  output['num_detections'] = num_detections\n",
        " \n",
        "  # The detected classes need to be integers.\n",
        "  output['detection_classes'] = output['detection_classes'].astype(np.int64)\n",
        "  output['boxes'] = [\n",
        "    {\"y\": int(box[0] * img_rgb.shape[0]), \"x\": int(box[1] * img_rgb.shape[1]), \"y2\": int(box[2] * img_rgb.shape[0]),\n",
        "     \"x2\": int(box[3] * img_rgb.shape[1])} for box in output['detection_boxes']]\n",
        " \n",
        "  # For each bounding box that was detected  \n",
        "  for idx in range(len(output['boxes'])):\n",
        " \n",
        "    # Extract the type of the object that was detected\n",
        "    obj_class = output[\"detection_classes\"][idx]\n",
        "     \n",
        "    # How confident the object detection model is on the object's type\n",
        "    score = int(output[\"detection_scores\"][idx] * 100)\n",
        "         \n",
        "    # Extract the bounding box\n",
        "    box = output[\"boxes\"][idx]\n",
        " \n",
        "    color = None\n",
        "    label_text = \"\"\n",
        " \n",
        "    # if obj_class == LABEL_PERSON:\n",
        "      # color = (0, 255, 255)\n",
        "      # label_text = \"Person \" + str(score)\n",
        "    # if obj_class == LABEL_CAR:\n",
        "      # color = (255, 255, 0)\n",
        "      # label_text = \"Car \" + str(score)\n",
        "    # if obj_class == LABEL_BUS:\n",
        "      # color = (255, 255, 0)\n",
        "      # label_text = \"Bus \" + str(score)\n",
        "    # if obj_class == LABEL_TRUCK:\n",
        "      # color = (255, 255, 0)\n",
        "      # label_text = \"Truck \" + str(score)\n",
        "    if obj_class == LABEL_STOP_SIGN:\n",
        "      color = (255, 255, 0)\n",
        "      label_text = \"Stop Sign \" + str(score)\n",
        "    if obj_class == LABEL_TRAFFIC_LIGHT:\n",
        "      color = (255, 255, 255)\n",
        "      label_text = \"Traffic Light \" + str(score)\n",
        "             \n",
        "      if model_traffic_lights:\n",
        "       \n",
        "              # Annotate the image and save it\n",
        "        img_traffic_light = img_rgb[box[\"y\"]:box[\"y2\"], box[\"x\"]:box[\"x2\"]]\n",
        "        img_inception = cv2.resize(img_traffic_light, (299, 299))\n",
        "         \n",
        "        img_inception = np.array([preprocess_input(img_inception)])\n",
        " \n",
        "        prediction = model_traffic_lights.predict(img_inception)\n",
        "        label = np.argmax(prediction)\n",
        "        score_light = str(int(np.max(prediction) * 100))\n",
        "        if label == 0:\n",
        "          label_text = \"Green \" + score_light\n",
        "        elif label == 1:\n",
        "          label_text = \"Yellow \" + score_light\n",
        "        elif label == 2:\n",
        "          label_text = \"Red \" + score_light\n",
        "        else:\n",
        "          label_text = 'NO-LIGHT'  # This is not a traffic light\n",
        " \n",
        "    # Use the score variable to indicate how confident we are it is a traffic light (in % terms)\n",
        "    # On the actual video frame, we display the confidence that the light is either red, green,\n",
        "    # yellow, or not a valid traffic light.\n",
        "    #CHANGE TO FIND OPTIMAL\n",
        "    if color and label_text and accept_box(output[\"boxes\"], idx, 5.0) and score > 80:\n",
        "      cv2.rectangle(img_rgb, (box[\"x\"], box[\"y\"]), (box[\"x2\"], box[\"y2\"]), color, 2)\n",
        "      cv2.putText(img_rgb, label_text, (box[\"x\"], box[\"y\"]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        " \n",
        "  output_frame = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
        "  return output_frame\n",
        " \n",
        "def double_shuffle(images, labels):\n",
        "  \"\"\"\n",
        "  Shuffle the images to add some randomness.\n",
        "  \"\"\"\n",
        "  indexes = np.random.permutation(len(images))\n",
        " \n",
        "  return [images[idx] for idx in indexes], [labels[idx] for idx in indexes]\n",
        " \n",
        "def reverse_preprocess_inception(img_preprocessed):\n",
        "  \"\"\"\n",
        "  Reverse the preprocessing process.\n",
        "  \"\"\"\n",
        "  img = img_preprocessed + 1.0\n",
        "  img = img * 127.5\n",
        "  return img.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hxwkH-bfZdFM",
        "outputId": "002e9153-8038-4fee-e288-f916413b9484"
      },
      "source": [
        "def show_history(history):\n",
        "  \"\"\"\n",
        "  Visualize the neural network model training history\n",
        "   \n",
        "  :param:history A record of training loss values and metrics values at \n",
        "                 successive epochs, as well as validation loss values \n",
        "                 and validation metrics values\n",
        "  \"\"\"\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "  plt.show()\n",
        " \n",
        "def Transfer(n_classes, freeze_layers=True):\n",
        "  \"\"\"\n",
        "  Use the InceptionV3 neural network architecture to perform transfer learning.\n",
        "     \n",
        "  :param:n_classes Number of classes\n",
        "  :param:freeze_layers If True, the network's parameters don't change.\n",
        "  :return The best neural network\n",
        "  \"\"\"\n",
        "  print(\"Loading Inception V3...\")\n",
        " \n",
        "  # To understand what the parameters mean, do a Google search 'inceptionv3 keras'. \n",
        "  # The first search result should send you to the Keras website, which has an \n",
        "  # explanation of what each of these parameters mean.\n",
        "  # input_top means we are removing the top part of the Inception model, which is the \n",
        "  # classifier. \n",
        "  # input_shape needs to have 3 channels, and needs to be at least 75x75 for the\n",
        "  # resolution.\n",
        "  # Our neural network will build off of the Inception V3 model (trained on the ImageNet\n",
        "  # data set).\n",
        "  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        " \n",
        "  print(\"Inception V3 has finished loading.\")\n",
        " \n",
        "  # Display the base network architecture\n",
        "  print('Layers: ', len(base_model.layers))\n",
        "  print(\"Shape:\", base_model.output_shape[1:])\n",
        "  print(\"Shape:\", base_model.output_shape)\n",
        "  print(\"Shape:\", base_model.outputs)\n",
        "  base_model.summary()\n",
        " \n",
        "  # Create the neural network. This network uses the Sequential\n",
        "  # architecture where each layer has one \n",
        "  # input tensor (e.g. vector, matrix, etc.) and one output tensor \n",
        "  top_model = Sequential()\n",
        " \n",
        "  # Our classifier model will build on top of the base model\n",
        "  top_model.add(base_model)\n",
        "  top_model.add(GlobalAveragePooling2D())\n",
        "  top_model.add(Dropout(0.5))\n",
        "  top_model.add(Dense(1024, activation='relu'))\n",
        "  top_model.add(BatchNormalization())\n",
        "  top_model.add(Dropout(0.5))\n",
        "  top_model.add(Dense(512, activation='relu'))\n",
        "  top_model.add(Dropout(0.5))\n",
        "  top_model.add(Dense(128, activation='relu'))\n",
        "  top_model.add(Dense(n_classes, activation='softmax'))\n",
        " \n",
        "  # Freeze layers in the model so that they cannot be trained (i.e. the\n",
        "  # parameters in the neural network will not change)\n",
        "  if freeze_layers:\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        " \n",
        "  return top_model\n",
        " \n",
        "# Perform image augmentation. \n",
        "# Image augmentation enables us to alter the available images\n",
        "# (e.g. rotate, flip, changing the hue, etc.) to generate more images that our\n",
        "# neural network can use for training...therefore preventing us from having to\n",
        "# collect more external images.\n",
        "datagen = ImageDataGenerator(rotation_range=5, width_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n",
        "                             zoom_range=[0.7, 1.5], height_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n",
        "                             horizontal_flip=True)\n",
        " \n",
        "shape = (299, 299)\n",
        " \n",
        "# Load the cropped traffic light images from the appropriate directory\n",
        "img_0_green = load_rgb_images(\"traffic_light_dataset/0_green/*\", shape)\n",
        "img_1_yellow = load_rgb_images(\"traffic_light_dataset/1_yellow/*\", shape)\n",
        "img_2_red = load_rgb_images(\"traffic_light_dataset/2_red/*\", shape)\n",
        "img_3_not_traffic_light = load_rgb_images(\"traffic_light_dataset/3_not/*\", shape)\n",
        " \n",
        "# Create a list of the labels that is the same length as the number of images in each\n",
        "# category\n",
        "# 0 = green\n",
        "# 1 = yellow\n",
        "# 2 = red\n",
        "# 3 = not a traffic light\n",
        "labels = [0] * len(img_0_green)\n",
        "labels.extend([1] * len(img_1_yellow))\n",
        "labels.extend([2] * len(img_2_red))\n",
        "labels.extend([3] * len(img_3_not_traffic_light))\n",
        " \n",
        "# Create NumPy array\n",
        "labels_np = np.ndarray(shape=(len(labels), 4))\n",
        "images_np = np.ndarray(shape=(len(labels), shape[0], shape[1], 3))\n",
        " \n",
        "# Create a list of all the images in the traffic lights data set\n",
        "img_all = []\n",
        "img_all.extend(img_0_green)\n",
        "img_all.extend(img_1_yellow)\n",
        "img_all.extend(img_2_red)\n",
        "img_all.extend(img_3_not_traffic_light)\n",
        " \n",
        "# Make sure we have the same number of images as we have labels\n",
        "assert len(img_all) == len(labels)  \n",
        " \n",
        "# Shuffle the images\n",
        "img_all = [preprocess_input(img) for img in img_all]\n",
        "(img_all, labels) = double_shuffle(img_all, labels)\n",
        " \n",
        "# Store images and labels in a NumPy array\n",
        "for idx in range(len(labels)):\n",
        "  images_np[idx] = img_all[idx]\n",
        "  labels_np[idx] = labels[idx]\n",
        "     \n",
        "print(\"Images: \", len(img_all))\n",
        "print(\"Labels: \", len(labels))\n",
        " \n",
        "# Perform one-hot encoding\n",
        "for idx in range(len(labels_np)):\n",
        "  # We have four integer labels, representing the different colors of the \n",
        "  # traffic lights.\n",
        "  labels_np[idx] = np.array(to_categorical(labels[idx], 4))\n",
        "     \n",
        "# Split the data set into a training set and a validation set\n",
        "# The training set is the portion of the data set that is used to \n",
        "#   determine the parameters (e.g. weights) of the neural network.\n",
        "# The validation set is the portion of the data set used to\n",
        "#   fine tune the model-specific parameters (i.e. hyperparameters) that are \n",
        "#   fixed before you train and test your neural network on the data. The \n",
        "#   validation set helps us select the final model (e.g. learning rate, \n",
        "#   number of hidden layers, number of hidden units, activation functions, \n",
        "#   number of epochs, etc.\n",
        "# In this case, 80% of the data set becomes training data, and 20% of the\n",
        "# data set becomes validation data.\n",
        "idx_split = int(len(labels_np) * 0.8)\n",
        "x_train = images_np[0:idx_split]\n",
        "x_valid = images_np[idx_split:]\n",
        "y_train = labels_np[0:idx_split]\n",
        "y_valid = labels_np[idx_split:]\n",
        " \n",
        "# Store a count of the number of traffic lights of each color\n",
        "cnt = collections.Counter(labels)\n",
        "print('Labels:', cnt)\n",
        "n = len(labels)\n",
        "print('0:', cnt[0])\n",
        "print('1:', cnt[1])\n",
        "print('2:', cnt[2])\n",
        "print('3:', cnt[3])\n",
        " \n",
        "# Calculate the weighting of each traffic light class\n",
        "class_weight = {0: n / cnt[0], 1: n / cnt[1], 2: n / cnt[2], 3: n / cnt[3]}\n",
        "print('Class weight:', class_weight)\n",
        " \n",
        "# Save the best model as traffic.h5\n",
        "checkpoint = ModelCheckpoint(\"traffic.h5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(min_delta=0.0005, patience=15, verbose=1)\n",
        " \n",
        "# Generate model using transfer learning\n",
        "model = Transfer(n_classes=4, freeze_layers=True)\n",
        " \n",
        "# Display a summary of the neural network model\n",
        "model.summary()\n",
        " \n",
        "# Generate a batch of randomly transformed images \n",
        "it_train = datagen.flow(x_train, y_train, batch_size=32)\n",
        " \n",
        "# Configure the model parameters for training\n",
        "model.compile(loss=categorical_crossentropy, optimizer=Adadelta(\n",
        "  lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0), metrics=['accuracy'])\n",
        " \n",
        "# Train the model on the image batches for a fixed number of epochs\n",
        "# Store a record of the error on the training data set and metrics values\n",
        "#   in the history object.\n",
        "history_object = model.fit(it_train, epochs=50, validation_data=(\n",
        "  x_valid, y_valid), shuffle=True, callbacks=[\n",
        "  checkpoint, early_stopping], class_weight=class_weight)\n",
        " \n",
        "# Display the training history\n",
        "show_history(history_object)\n",
        " \n",
        "# Get the loss value and metrics values on the validation data set\n",
        "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n",
        " \n",
        "print('Saving the validation data set...')\n",
        " \n",
        "print('Length of the validation data set:', len(x_valid))\n",
        " \n",
        "# Go through the validation data set, and see how the model did on each image\n",
        "for idx in range(len(x_valid)):\n",
        " \n",
        "  # Make the image a NumPy array\n",
        "  img_as_ar = np.array([x_valid[idx]])\n",
        " \n",
        "  # Generate predictions    \n",
        "  prediction = model.predict(img_as_ar)\n",
        " \n",
        "  # Determine what the label is based on the highest probability\n",
        "  label = np.argmax(prediction)\n",
        " \n",
        "  # Create the name of the directory and the file for the validation data set\n",
        "  # After each run, delete this out_valid/ directory so that old files are not\n",
        "  # hanging around in there.\n",
        "  file_name = str(idx) + \"_\" + str(label) + \"_\" + str(np.argmax(str(y_valid[idx]))) + \".jpg\"\n",
        "  img = img_as_ar[0]\n",
        " \n",
        "  # Reverse the image preprocessing process\n",
        "  img = reverse_preprocess_inception(img)\n",
        " \n",
        "  # Save the image file\n",
        "  cv2.imwrite(file_name, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        " \n",
        "print('The validation data set has been saved!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images:  944\n",
            "Labels:  944\n",
            "Labels: Counter({0: 330, 2: 316, 3: 182, 1: 116})\n",
            "0: 330\n",
            "1: 116\n",
            "2: 316\n",
            "3: 182\n",
            "Class weight: {0: 2.860606060606061, 1: 8.137931034482758, 2: 2.9873417721518987, 3: 5.186813186813187}\n",
            "Loading Inception V3...\n",
            "Inception V3 has finished loading.\n",
            "Layers:  311\n",
            "Shape: (8, 8, 2048)\n",
            "Shape: (None, 8, 8, 2048)\n",
            "Shape: [<KerasTensor: shape=(None, 8, 8, 2048) dtype=float32 (created by layer 'mixed10')>]\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 149, 149, 32) 864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 149, 149, 32) 96          conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 149, 149, 32) 0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 147, 147, 32) 9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 147, 147, 32) 96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 147, 147, 32) 0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 147, 147, 64) 18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 147, 147, 64) 192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 147, 147, 64) 0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 73, 73, 80)   240         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 73, 73, 80)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 71, 71, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 71, 71, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 71, 71, 192)  0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 35, 35, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 35, 35, 48)   144         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 35, 35, 96)   288         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 35, 35, 48)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 35, 35, 96)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 35, 35, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 35, 35, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 35, 35, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 35, 35, 64)   192         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 35, 35, 32)   96          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 35, 35, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 35, 35, 64)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 35, 35, 32)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 35, 35, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 35, 35, 48)   144         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 35, 35, 96)   288         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 35, 35, 48)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 35, 35, 96)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 35, 35, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 35, 35, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 35, 35, 64)   192         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 35, 35, 64)   192         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 35, 35, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 35, 35, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 35, 35, 64)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 35, 35, 64)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 35, 35, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 35, 35, 48)   144         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 35, 35, 96)   288         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 35, 35, 48)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 35, 35, 96)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 35, 35, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 35, 35, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 35, 35, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 35, 35, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 35, 35, 64)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 35, 35, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 35, 35, 64)   192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 35, 35, 64)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 35, 35, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 35, 35, 96)   288         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 35, 35, 96)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 17, 17, 96)   82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 17, 17, 384)  1152        conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 17, 17, 96)   288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 17, 17, 384)  0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 17, 17, 96)   0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 17, 17, 128)  114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 17, 17, 128)  384         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 17, 17, 128)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 17, 17, 128)  114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 17, 17, 192)  172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 17, 17, 192)  172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 17, 17, 192)  576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 17, 17, 192)  576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 17, 17, 192)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 17, 17, 192)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 17, 17, 160)  179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 17, 17, 160)  480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 17, 17, 160)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 17, 17, 160)  179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 17, 17, 192)  215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 17, 17, 192)  215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 17, 17, 192)  576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 17, 17, 192)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 17, 17, 160)  179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 17, 17, 160)  480         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 17, 17, 160)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 17, 17, 160)  179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 17, 17, 192)  215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 17, 17, 192)  215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 17, 17, 192)  576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 17, 17, 192)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 17, 17, 192)  258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 17, 17, 192)  258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 17, 17, 192)  258048      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 8, 8, 320)    552960      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 8, 8, 320)    960         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 8, 8, 192)    576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 8, 8, 320)    0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_259[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 8, 8, 448)    1344        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 8, 8, 448)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 384)    1548288     activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 384)    1152        conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 8, 8, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 384)    1152        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 384)    1152        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 8, 8, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 8, 8, 384)    1152        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 8, 8, 320)    960         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 8, 8, 192)    576         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 8, 8, 320)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_266[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_270[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 8, 8, 192)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_264[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 448)    1344        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 8, 8, 448)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 384)    1548288     activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 8, 8, 384)    1152        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 8, 8, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 8, 8, 384)    1152        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 320)    960         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 8, 8, 192)    576         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 8, 8, 320)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_275[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_279[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 8, 8, 192)    0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_273[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_281[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "batch_normalization_284 (Bat (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 24,496,036\n",
            "Trainable params: 2,691,204\n",
            "Non-trainable params: 21,804,832\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 207s 8s/step - loss: 7.4348 - accuracy: 0.3576 - val_loss: 1.0382 - val_accuracy: 0.5503\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.03825, saving model to traffic.h5\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 205s 9s/step - loss: 5.5411 - accuracy: 0.4556 - val_loss: 0.8424 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.03825 to 0.84239, saving model to traffic.h5\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 4.4590 - accuracy: 0.5417 - val_loss: 0.7804 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.84239 to 0.78039, saving model to traffic.h5\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 4.1101 - accuracy: 0.5536 - val_loss: 0.6702 - val_accuracy: 0.7619\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.78039 to 0.67016, saving model to traffic.h5\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 3.8619 - accuracy: 0.6132 - val_loss: 0.5939 - val_accuracy: 0.8095\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.67016 to 0.59385, saving model to traffic.h5\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 3.7736 - accuracy: 0.6079 - val_loss: 0.5293 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.59385 to 0.52934, saving model to traffic.h5\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 3.7475 - accuracy: 0.6331 - val_loss: 0.5041 - val_accuracy: 0.8254\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.52934 to 0.50413, saving model to traffic.h5\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 3.2885 - accuracy: 0.6728 - val_loss: 0.5132 - val_accuracy: 0.8201\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.50413\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 3.2836 - accuracy: 0.6609 - val_loss: 0.4849 - val_accuracy: 0.8360\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.50413 to 0.48493, saving model to traffic.h5\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 2.9858 - accuracy: 0.6914 - val_loss: 0.4527 - val_accuracy: 0.8254\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.48493 to 0.45270, saving model to traffic.h5\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 2.7940 - accuracy: 0.6993 - val_loss: 0.4293 - val_accuracy: 0.8360\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.45270 to 0.42934, saving model to traffic.h5\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 3.0234 - accuracy: 0.6781 - val_loss: 0.4364 - val_accuracy: 0.8413\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.42934\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 3.1186 - accuracy: 0.6834 - val_loss: 0.3887 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.42934 to 0.38872, saving model to traffic.h5\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 3.0851 - accuracy: 0.6954 - val_loss: 0.4181 - val_accuracy: 0.8519\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.38872\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.6847 - accuracy: 0.7417 - val_loss: 0.4100 - val_accuracy: 0.8413\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.38872\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 3.0229 - accuracy: 0.7033 - val_loss: 0.4053 - val_accuracy: 0.8360\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.38872\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.5069 - accuracy: 0.7430 - val_loss: 0.3798 - val_accuracy: 0.8519\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.38872 to 0.37979, saving model to traffic.h5\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.6043 - accuracy: 0.7523 - val_loss: 0.3684 - val_accuracy: 0.8466\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.37979 to 0.36841, saving model to traffic.h5\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.4657 - accuracy: 0.7497 - val_loss: 0.3872 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.36841\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 205s 9s/step - loss: 2.4777 - accuracy: 0.7536 - val_loss: 0.3517 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.36841 to 0.35173, saving model to traffic.h5\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.5410 - accuracy: 0.7497 - val_loss: 0.3576 - val_accuracy: 0.8519\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.35173\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.4167 - accuracy: 0.7523 - val_loss: 0.3323 - val_accuracy: 0.8783\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.35173 to 0.33233, saving model to traffic.h5\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.5169 - accuracy: 0.7629 - val_loss: 0.3383 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.33233\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.3855 - accuracy: 0.7576 - val_loss: 0.3577 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.33233\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.3608 - accuracy: 0.7656 - val_loss: 0.3561 - val_accuracy: 0.8730\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.33233\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.4689 - accuracy: 0.7735 - val_loss: 0.3476 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.33233\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.3175 - accuracy: 0.7762 - val_loss: 0.3279 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.33233 to 0.32788, saving model to traffic.h5\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.3198 - accuracy: 0.7801 - val_loss: 0.3284 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.32788\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.1425 - accuracy: 0.7881 - val_loss: 0.3161 - val_accuracy: 0.9101\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.32788 to 0.31608, saving model to traffic.h5\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 202s 9s/step - loss: 2.2421 - accuracy: 0.7934 - val_loss: 0.3127 - val_accuracy: 0.8783\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.31608 to 0.31272, saving model to traffic.h5\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.2738 - accuracy: 0.7974 - val_loss: 0.3243 - val_accuracy: 0.8783\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.31272\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 203s 8s/step - loss: 2.1317 - accuracy: 0.8066 - val_loss: 0.3155 - val_accuracy: 0.9048\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.31272\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.2528 - accuracy: 0.7748 - val_loss: 0.2878 - val_accuracy: 0.9312\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.31272 to 0.28777, saving model to traffic.h5\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.1072 - accuracy: 0.7762 - val_loss: 0.2934 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.28777\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 200s 8s/step - loss: 2.1166 - accuracy: 0.8013 - val_loss: 0.3066 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.28777\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 204s 8s/step - loss: 2.2646 - accuracy: 0.7934 - val_loss: 0.2951 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.28777\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.0887 - accuracy: 0.8013 - val_loss: 0.2909 - val_accuracy: 0.9365\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.28777\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.1956 - accuracy: 0.7974 - val_loss: 0.2937 - val_accuracy: 0.9312\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.28777\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.0465 - accuracy: 0.8026 - val_loss: 0.2855 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.28777 to 0.28545, saving model to traffic.h5\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 1.7154 - accuracy: 0.8437 - val_loss: 0.2819 - val_accuracy: 0.9153\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.28545 to 0.28188, saving model to traffic.h5\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.1855 - accuracy: 0.7815 - val_loss: 0.2969 - val_accuracy: 0.9048\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.28188\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 1.8278 - accuracy: 0.8252 - val_loss: 0.2876 - val_accuracy: 0.9153\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.28188\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 201s 8s/step - loss: 2.1652 - accuracy: 0.8132 - val_loss: 0.2975 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.28188\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 1.9503 - accuracy: 0.8026 - val_loss: 0.2676 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.28188 to 0.26756, saving model to traffic.h5\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 2.0132 - accuracy: 0.8199 - val_loss: 0.2833 - val_accuracy: 0.9153\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.26756\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 203s 8s/step - loss: 1.8938 - accuracy: 0.8132 - val_loss: 0.2849 - val_accuracy: 0.9101\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.26756\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 203s 9s/step - loss: 2.1118 - accuracy: 0.7921 - val_loss: 0.2818 - val_accuracy: 0.9048\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.26756\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 203s 8s/step - loss: 1.8885 - accuracy: 0.8172 - val_loss: 0.2874 - val_accuracy: 0.9101\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.26756\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 203s 8s/step - loss: 1.9344 - accuracy: 0.8026 - val_loss: 0.2785 - val_accuracy: 0.9153\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.26756\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 202s 8s/step - loss: 1.7549 - accuracy: 0.8318 - val_loss: 0.2681 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.26756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.26814889907836914\n",
            "Validation accuracy: 0.920634925365448\n",
            "Saving the validation data set...\n",
            "Length of the validation data set: 189\n",
            "The validation data set has been saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "8bcg2iwhIPYG",
        "outputId": "6478a908-f81d-4157-84c9-d0a15720fccd"
      },
      "source": [
        "time_list = []\n",
        "filename = 'cabc30fc-e7726578.mp4'\n",
        "file_size = (1280,720) # Assumes 1920x1080 mp4\n",
        "scale_ratio = 1 # Option to scale to fraction of original size. \n",
        " \n",
        "# We want to save the output to a video file\n",
        "output_filename = 'Driving_result1.mp4'\n",
        "output_frames_per_second = 30.0\n",
        " \n",
        "# Load the SSD neural network that is trained on the COCO data set\n",
        "model_ssd = load_ssd_coco()\n",
        " \n",
        "# Load the trained neural network\n",
        "model_traffic_lights_nn = keras.models.load_model(\"traffic.h5\")\n",
        " \n",
        "def main():\n",
        " \n",
        "  # Load a video\n",
        "  cap = cv2.VideoCapture(filename)\n",
        " \n",
        "  # Create a VideoWriter object so we can save the video output\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "  result = cv2.VideoWriter(output_filename,  \n",
        "                           fourcc, \n",
        "                           output_frames_per_second, \n",
        "                           file_size) \n",
        "     \n",
        "  # Process the video\n",
        "  while cap.isOpened():\n",
        "         \n",
        "    # Capture one frame at a time\n",
        "    success, frame = cap.read() \n",
        "         \n",
        "    # Do we have a video frame? If true, proceed.\n",
        "    if success:\n",
        "\n",
        "      #Time the computation\n",
        "      start_time = time.time()\n",
        "\n",
        "      # Resize the frame\n",
        "      width = int(frame.shape[1] * scale_ratio)\n",
        "      height = int(frame.shape[0] * scale_ratio)\n",
        "      frame = cv2.resize(frame, (width, height))\n",
        "             \n",
        "      # Store the original frame\n",
        "      original_frame = frame.copy()\n",
        " \n",
        "      output_frame = perform_object_detection_video(\n",
        "        model_ssd, frame, model_traffic_lights=model_traffic_lights_nn)\n",
        "      \n",
        "      time_list.append(time.time()-start_time)\n",
        " \n",
        "      # Write the frame to the output video file\n",
        "      result.write(output_frame)\n",
        "             \n",
        "    # No more video frames left\n",
        "    else:\n",
        "      break\n",
        "  \n",
        "  print('The average time taken for computation of each frame is',mean(time_list))\n",
        "  # Stop when the video is finished\n",
        "  cap.release()\n",
        "     \n",
        "  # Release the video recording\n",
        "  result.release()\n",
        "     \n",
        "  # Close all windows\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model path:  /root/.keras/datasets/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-860c63d7b81d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-860c63d7b81d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The average time taken for computation of each frame is'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;31m# Stop when the video is finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ven4IwlgN3IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fd0797-231d-40ee-c996-ceb201c454b4"
      },
      "source": [
        "FILENAME = \"stop_sign.png\"\n",
        " \n",
        "# Load the Inception V3 model\n",
        "model_inception = InceptionV3(weights='imagenet', include_top=True, input_shape=(299,299,3))\n",
        " \n",
        "# Resize the image\n",
        "img = cv2.resize(preprocess_input(cv2.imread(FILENAME)), (299, 299))\n",
        " \n",
        "# Generate predictions\n",
        "out_inception = model_inception.predict(np.array([img]))\n",
        " \n",
        "# Decode the predictions\n",
        "out_inception = imagenet_utils.decode_predictions(out_inception)\n",
        " \n",
        "print(\"Prediction for \", FILENAME , \": \", out_inception[0][0][1], out_inception[0][0][2], \"%\")\n",
        " \n",
        "# Show model summary data\n",
        "model_inception.summary()\n",
        " \n",
        "# Detect traffic light color in a batch of image files\n",
        "files = get_files('test_images/*.png')\n",
        " \n",
        "# Load the SSD neural network that is trained on the COCO data set\n",
        "model_ssd = load_ssd_coco()\n",
        " \n",
        "# Load the trained neural network\n",
        "model_traffic_lights_nn = keras.models.load_model(\"traffic.h5\")\n",
        " \n",
        "# Go through all image files, and detect the traffic light color. \n",
        "for file in files:\n",
        "  (img, out, file_name) = perform_object_detection(\n",
        "    model_ssd, file, save_annotated=True, model_traffic_lights=model_traffic_lights_nn)\n",
        "  cv2.imwrite('Stop.png',img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for  stop_sign.png :  traffic_light 0.18601295 %\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 149, 149, 32) 96          conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 149, 149, 32) 0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 147, 147, 32) 9216        activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 147, 147, 32) 96          conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 147, 147, 32) 0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 147, 147, 64) 18432       activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 147, 147, 64) 192         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 147, 147, 64) 0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 73, 73, 64)   0           activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 73, 73, 80)   240         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 73, 73, 80)   0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 71, 71, 192)  138240      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 71, 71, 192)  576         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 71, 71, 192)  0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 35, 35, 192)  0           activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 35, 35, 64)   192         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 35, 35, 64)   0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 35, 35, 96)   55296       activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 35, 35, 48)   144         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 35, 35, 96)   288         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 35, 35, 48)   0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 35, 35, 96)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_27 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 35, 35, 64)   76800       activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 35, 35, 96)   82944       activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 35, 35, 64)   192         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 35, 35, 64)   192         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 35, 35, 96)   288         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 35, 35, 32)   96          conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 35, 35, 64)   0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 35, 35, 64)   0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 35, 35, 96)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 35, 35, 32)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_287[0][0]             \n",
            "                                                                 activation_289[0][0]             \n",
            "                                                                 activation_292[0][0]             \n",
            "                                                                 activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 35, 35, 64)   192         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 35, 35, 64)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 35, 35, 96)   55296       activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 35, 35, 48)   144         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 35, 35, 96)   288         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 35, 35, 48)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 35, 35, 96)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 35, 35, 64)   76800       activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 35, 35, 96)   82944       activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 35, 35, 64)   192         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 35, 35, 64)   192         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 35, 35, 96)   288         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 35, 35, 64)   192         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 35, 35, 64)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 35, 35, 64)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 35, 35, 96)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 35, 35, 64)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_294[0][0]             \n",
            "                                                                 activation_296[0][0]             \n",
            "                                                                 activation_299[0][0]             \n",
            "                                                                 activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 35, 35, 64)   0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 35, 35, 96)   55296       activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 35, 35, 48)   144         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 35, 35, 96)   288         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 35, 35, 48)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 35, 35, 96)   0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 35, 35, 64)   76800       activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 35, 35, 96)   82944       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 35, 35, 64)   192         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 35, 35, 64)   192         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 35, 35, 64)   192         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 35, 35, 64)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 35, 35, 64)   0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 35, 35, 96)   0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 35, 35, 64)   0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_301[0][0]             \n",
            "                                                                 activation_303[0][0]             \n",
            "                                                                 activation_306[0][0]             \n",
            "                                                                 activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 35, 35, 64)   192         conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 35, 35, 64)   0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 35, 35, 96)   55296       activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 35, 35, 96)   288         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 35, 35, 96)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 17, 17, 96)   82944       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 17, 17, 384)  1152        conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 17, 17, 96)   288         conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 17, 17, 384)  0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 17, 17, 96)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_308[0][0]             \n",
            "                                                                 activation_311[0][0]             \n",
            "                                                                 max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 17, 17, 128)  384         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 17, 17, 128)  0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 17, 17, 128)  114688      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 17, 17, 128)  384         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 17, 17, 128)  0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 17, 17, 128)  114688      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 17, 17, 128)  384         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 17, 17, 128)  384         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 17, 17, 128)  0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 17, 17, 128)  0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 17, 17, 128)  114688      activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 17, 17, 128)  114688      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 17, 17, 128)  384         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 17, 17, 128)  384         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 17, 17, 128)  0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 17, 17, 128)  0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 17, 17, 192)  172032      activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 17, 17, 192)  172032      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 17, 17, 192)  576         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 17, 17, 192)  576         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 17, 17, 192)  576         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 17, 17, 192)  576         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 17, 17, 192)  0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 17, 17, 192)  0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 17, 17, 192)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 17, 17, 192)  0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_312[0][0]             \n",
            "                                                                 activation_315[0][0]             \n",
            "                                                                 activation_320[0][0]             \n",
            "                                                                 activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 17, 17, 160)  480         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 17, 17, 160)  0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 17, 17, 160)  179200      activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 17, 17, 160)  480         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 17, 17, 160)  0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 17, 17, 160)  179200      activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 17, 17, 160)  480         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 17, 17, 160)  480         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 17, 17, 160)  0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 17, 17, 160)  0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 17, 17, 160)  179200      activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 17, 17, 160)  179200      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 17, 17, 160)  480         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 17, 17, 160)  0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 17, 17, 160)  0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 17, 17, 192)  215040      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 17, 17, 192)  215040      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 17, 17, 192)  576         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 17, 17, 192)  576         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 17, 17, 192)  0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 17, 17, 192)  0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 17, 17, 192)  0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 17, 17, 192)  0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_322[0][0]             \n",
            "                                                                 activation_325[0][0]             \n",
            "                                                                 activation_330[0][0]             \n",
            "                                                                 activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 17, 17, 160)  480         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 17, 17, 160)  0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 17, 17, 160)  179200      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 17, 17, 160)  0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 17, 17, 160)  179200      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 17, 17, 160)  480         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 17, 17, 160)  0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 17, 17, 160)  0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 17, 17, 160)  179200      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 17, 17, 160)  480         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 17, 17, 160)  0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 17, 17, 160)  0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 17, 17, 192)  215040      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 17, 17, 192)  215040      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 17, 17, 192)  576         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 17, 17, 192)  576         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 17, 17, 192)  576         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 17, 17, 192)  576         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 17, 17, 192)  0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 17, 17, 192)  0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 17, 17, 192)  0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 17, 17, 192)  0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_332[0][0]             \n",
            "                                                                 activation_335[0][0]             \n",
            "                                                                 activation_340[0][0]             \n",
            "                                                                 activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 17, 17, 192)  258048      activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 17, 17, 192)  258048      activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 17, 17, 192)  576         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 17, 17, 192)  0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 17, 17, 192)  0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 17, 17, 192)  258048      activation_343[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 17, 17, 192)  258048      activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 17, 17, 192)  576         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 17, 17, 192)  576         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 17, 17, 192)  0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 17, 17, 192)  0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 17, 17, 192)  258048      activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 17, 17, 192)  258048      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 17, 17, 192)  0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 17, 17, 192)  0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_342[0][0]             \n",
            "                                                                 activation_345[0][0]             \n",
            "                                                                 activation_350[0][0]             \n",
            "                                                                 activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 17, 17, 192)  576         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 17, 17, 192)  0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 17, 17, 192)  258048      activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 17, 17, 192)  0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 17, 17, 192)  258048      activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 17, 17, 192)  576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 17, 17, 192)  576         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 17, 17, 192)  0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 17, 17, 192)  0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 8, 8, 320)    552960      activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 8, 8, 192)    331776      activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 8, 8, 320)    960         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 8, 8, 192)    576         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 8, 8, 320)    0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 8, 8, 192)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_353[0][0]             \n",
            "                                                                 activation_357[0][0]             \n",
            "                                                                 max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 8, 8, 448)    1344        conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 8, 8, 448)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 8, 8, 384)    1548288     activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 8, 8, 384)    1152        conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 8, 8, 384)    1152        conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 8, 8, 384)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 8, 8, 384)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 8, 8, 384)    442368      activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 8, 8, 384)    442368      activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 8, 8, 384)    442368      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 8, 8, 384)    442368      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 8, 8, 384)    1152        conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 8, 8, 384)    1152        conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 8, 8, 384)    1152        conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 8, 8, 384)    1152        conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 8, 8, 320)    960         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 8, 8, 384)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 8, 8, 384)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 8, 8, 384)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 8, 8, 384)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 8, 8, 192)    576         conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 8, 8, 320)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_360[0][0]             \n",
            "                                                                 activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 8, 8, 768)    0           activation_364[0][0]             \n",
            "                                                                 activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 8, 8, 192)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_358[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_6[0][0]              \n",
            "                                                                 activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 8, 8, 448)    1344        conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 8, 8, 448)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 8, 8, 384)    1548288     activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 8, 8, 384)    1152        conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 8, 8, 384)    1152        conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 8, 8, 384)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 8, 8, 384)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 8, 8, 384)    442368      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 8, 8, 384)    442368      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 8, 8, 384)    442368      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 8, 8, 384)    442368      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 8, 8, 384)    1152        conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 8, 8, 384)    1152        conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 8, 8, 384)    1152        conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 8, 8, 384)    1152        conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 8, 8, 320)    960         conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 8, 8, 384)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 8, 8, 384)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 8, 8, 384)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 8, 8, 384)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 8, 8, 192)    576         conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 8, 8, 320)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_369[0][0]             \n",
            "                                                                 activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 8, 8, 768)    0           activation_373[0][0]             \n",
            "                                                                 activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 8, 8, 192)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_367[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "Model path:  /root/.keras/datasets/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\n",
            "num_detections: tf.Tensor([100.], shape=(1,), dtype=float32) 100\n",
            "Detection classes: [13.  3. 13.  1. 13.  3. 13.  8.  1.  4. 37.  3. 14.  1.  1.  1.  1.  3.\n",
            "  3.  1.  3.  1.  1.  3.  1.  3. 77.  1.  3.  3.  1. 85.  1.  1.  6.  1.\n",
            " 10.  1.  3.  3.  3. 14.  8.  3. 28. 56. 82.  1.  1.  3.  3. 20. 14.  1.\n",
            " 85. 13.  1.  3. 10.  3. 14.  1.  1. 37.  1.  3.  3.  1.  3.  3.  3.  1.\n",
            "  1.  1.  3.  1.  3.  3. 85.  1.  3.  3.  3.  3.  1.  1.  1.  1.  1. 85.\n",
            " 13.  3. 51.  1.  1.  1. 53.  1.  3.  4.]\n",
            "Detection Boxes: [[3.6279058e-01 4.6671507e-01 5.3021944e-01 5.5754662e-01]\n",
            " [7.2055060e-01 5.1370576e-02 9.9857384e-01 4.1900057e-01]\n",
            " [5.7226855e-01 4.7724581e-01 7.0372623e-01 5.4883945e-01]\n",
            " [7.8560275e-01 1.7100862e-01 8.5605019e-01 2.1276540e-01]\n",
            " [5.0943273e-01 4.7371814e-01 6.9680792e-01 5.5565059e-01]\n",
            " [8.2707286e-01 1.1193901e-03 1.0000000e+00 8.6839624e-02]\n",
            " [3.5283482e-01 4.6739128e-01 6.6167939e-01 5.6093699e-01]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [8.0235356e-01 2.2666413e-01 8.5487527e-01 2.8059167e-01]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [8.1398094e-01 7.0339209e-01 8.4530640e-01 7.2080094e-01]\n",
            " [8.4742552e-01 2.3891039e-02 9.9832529e-01 9.6816160e-02]\n",
            " [2.8318763e-01 6.8943697e-01 4.5335811e-01 7.4027556e-01]\n",
            " [7.9690021e-01 3.1935841e-01 8.5872191e-01 3.4784257e-01]\n",
            " [7.9257584e-01 2.1809784e-01 8.5203147e-01 2.7061614e-01]\n",
            " [7.8594410e-01 1.8429922e-01 8.5519111e-01 2.1857439e-01]\n",
            " [8.2043684e-01 2.3335665e-01 8.5675859e-01 2.8504890e-01]\n",
            " [8.8781637e-01 1.7743856e-03 9.9950856e-01 7.3560663e-02]\n",
            " [8.1519276e-01 3.6304444e-02 1.0000000e+00 1.4746070e-01]\n",
            " [7.8484505e-01 1.9206624e-01 8.5408038e-01 2.4944903e-01]\n",
            " [8.5021996e-01 4.7884058e-02 9.9968684e-01 1.1655590e-01]\n",
            " [7.8177917e-01 2.0662233e-01 8.5306144e-01 2.6253143e-01]\n",
            " [7.8661418e-01 3.2279345e-01 8.5854375e-01 3.5684910e-01]\n",
            " [8.4271109e-01 4.2030066e-02 9.9738836e-01 1.9341753e-01]\n",
            " [8.3224136e-01 2.3943859e-01 8.7285620e-01 2.8357375e-01]\n",
            " [8.2302403e-01 4.9366236e-02 9.9885654e-01 3.5698989e-01]\n",
            " [2.8318763e-01 6.8943697e-01 4.5335811e-01 7.4027556e-01]\n",
            " [7.7548993e-01 3.1470650e-01 8.5397470e-01 3.4871787e-01]\n",
            " [7.8224969e-01 4.5849204e-02 1.0000000e+00 5.5346674e-01]\n",
            " [7.5666487e-01 5.0885648e-02 9.9974370e-01 2.0556101e-01]\n",
            " [7.7627140e-01 1.9455287e-01 8.5873121e-01 2.7730072e-01]\n",
            " [5.7085681e-01 4.7745049e-01 7.0178819e-01 5.4932952e-01]\n",
            " [7.2705197e-01 4.0476531e-02 1.0000000e+00 4.2091888e-01]\n",
            " [7.7939987e-01 1.6506073e-01 8.5958493e-01 2.3335600e-01]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [7.7801108e-01 2.1465924e-01 8.5812640e-01 2.9759428e-01]\n",
            " [2.8318763e-01 6.8943697e-01 4.5335811e-01 7.4027556e-01]\n",
            " [7.9481560e-01 2.9860550e-01 8.5679191e-01 3.3882856e-01]\n",
            " [8.6594999e-01 0.0000000e+00 9.9774003e-01 1.2494133e-01]\n",
            " [7.1150506e-01 8.7072104e-02 8.8045573e-01 3.7545720e-01]\n",
            " [8.5344309e-01 9.5922686e-04 1.0000000e+00 5.5208750e-02]\n",
            " [3.6216679e-01 4.6675578e-01 5.3381974e-01 5.5691820e-01]\n",
            " [8.2707286e-01 1.1193901e-03 1.0000000e+00 8.6839624e-02]\n",
            " [8.2242996e-01 8.0097280e-04 8.9249092e-01 4.7091737e-02]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [7.2092026e-01 4.9560696e-02 1.0000000e+00 4.2462483e-01]\n",
            " [3.6216679e-01 4.6675578e-01 5.3381974e-01 5.5691820e-01]\n",
            " [7.8862011e-01 1.5038809e-01 8.5769415e-01 2.1853718e-01]\n",
            " [7.7866811e-01 2.4088748e-01 8.5888845e-01 3.2315382e-01]\n",
            " [7.4661684e-01 0.0000000e+00 1.0000000e+00 6.5600371e-01]\n",
            " [9.2972904e-01 0.0000000e+00 9.9937075e-01 9.2059262e-02]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [5.0943273e-01 4.7371814e-01 6.9680792e-01 5.5565059e-01]\n",
            " [8.1033123e-01 2.3125932e-01 8.8227654e-01 2.8421214e-01]\n",
            " [3.5946524e-01 4.6686915e-01 5.2984589e-01 5.5752897e-01]\n",
            " [2.8318763e-01 6.8943697e-01 4.5335811e-01 7.4027556e-01]\n",
            " [7.7337253e-01 1.1544144e-01 9.8719394e-01 2.3769364e-01]\n",
            " [8.1565565e-01 2.8560311e-04 9.3687326e-01 8.3514273e-02]\n",
            " [3.9178744e-01 0.0000000e+00 4.9109533e-01 1.9328244e-02]\n",
            " [8.4413511e-01 1.9950084e-03 9.5214325e-01 6.5201387e-02]\n",
            " [3.5777253e-01 4.6553543e-01 6.7846304e-01 5.5865186e-01]\n",
            " [8.6029279e-01 4.7410324e-02 9.9787521e-01 9.4577983e-02]\n",
            " [7.8038055e-01 2.7575982e-01 8.5707575e-01 3.4772718e-01]\n",
            " [8.1307536e-01 7.0084655e-01 8.4081489e-01 7.1603501e-01]\n",
            " [7.9862100e-01 2.3169354e-01 8.5696799e-01 3.0406037e-01]\n",
            " [8.0209446e-01 4.9796153e-02 9.4999659e-01 1.2228216e-01]\n",
            " [8.3063722e-01 1.7742533e-03 9.1967297e-01 5.7338312e-02]\n",
            " [7.7099681e-01 1.7875870e-01 8.5181344e-01 2.2644533e-01]\n",
            " [9.0957528e-01 3.5643816e-01 9.9899942e-01 4.1780961e-01]\n",
            " [8.6983502e-01 4.8486304e-02 9.9837768e-01 9.5356688e-02]\n",
            " [8.6860693e-01 0.0000000e+00 9.6437824e-01 9.9424712e-02]\n",
            " [8.0624968e-01 2.1320410e-01 8.5549182e-01 2.5225902e-01]\n",
            " [7.7357745e-01 1.5524103e-01 9.9327433e-01 2.5608841e-01]\n",
            " [6.9681734e-01 0.0000000e+00 8.1662601e-01 5.4620425e-03]\n",
            " [7.3114431e-01 1.5614104e-01 9.9697173e-01 3.7564778e-01]\n",
            " [7.8132540e-01 1.5062693e-01 9.3187910e-01 2.2404945e-01]\n",
            " [8.7682378e-01 6.4428449e-02 1.0000000e+00 2.6735368e-01]\n",
            " [9.0530962e-01 2.4907701e-03 9.9955875e-01 1.1563419e-01]\n",
            " [2.8318763e-01 6.8943697e-01 4.5335811e-01 7.4027556e-01]\n",
            " [6.4091992e-01 0.0000000e+00 8.2559836e-01 4.2282799e-03]\n",
            " [5.9389377e-01 3.0583173e-02 1.0000000e+00 4.4482064e-01]\n",
            " [9.0807116e-01 1.2092127e-01 9.9876142e-01 1.9094656e-01]\n",
            " [8.6550188e-01 3.5340032e-01 9.9685550e-01 4.2204651e-01]\n",
            " [7.8701156e-01 0.0000000e+00 9.9895364e-01 1.1854386e-01]\n",
            " [7.4530143e-01 1.2397377e-01 8.5820144e-01 1.6612963e-01]\n",
            " [8.4114552e-01 2.1427698e-02 9.9840391e-01 9.5537528e-02]\n",
            " [1.4276817e-01 5.7196307e-01 1.7009372e-01 5.8235836e-01]\n",
            " [8.2759058e-01 2.3581034e-01 9.0135229e-01 2.8679222e-01]\n",
            " [8.0769753e-01 2.1381040e-01 8.5978997e-01 2.8996891e-01]\n",
            " [3.8399357e-01 4.6891353e-01 7.0988637e-01 5.5826104e-01]\n",
            " [4.2292914e-01 4.6600044e-01 5.4700583e-01 5.5782199e-01]\n",
            " [9.5627958e-01 0.0000000e+00 9.9921066e-01 1.0419083e-01]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [1.4176771e-01 5.7385212e-01 1.6433662e-01 5.8346111e-01]\n",
            " [8.5867369e-01 4.5827471e-02 9.2087889e-01 9.1804497e-02]\n",
            " [9.2843330e-01 1.7586100e-01 9.9954760e-01 2.3035663e-01]\n",
            " [7.2146058e-01 4.3780610e-02 9.9284279e-01 4.2134535e-01]\n",
            " [7.7725536e-01 1.7577478e-01 8.3542603e-01 2.1443909e-01]\n",
            " [8.4420067e-01 4.8830472e-03 9.3226284e-01 1.0728146e-01]\n",
            " [8.2043976e-01 1.3932064e-03 9.9912292e-01 8.6537220e-02]]\n",
            "test_images/stop_sign.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9hWHbjVQ7Dl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865c1f39-bca7-4825-ec05-32bae406af1b"
      },
      "source": [
        "from statistics import *\n",
        "median(time_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.542952299118042"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxLTryklujyx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}